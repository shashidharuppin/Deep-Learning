{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face and Eye Detection on Image using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Load face cascade and hair cascade from haarcascades folder\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "#Read image in img and convert it to grayscale and store in gray.\n",
    "#Image is converted to grayscale, as face cascade doesn't require to operate on coloured images.\n",
    "img = cv2.imread('C:\\\\Users\\\\UPPI\\\\Downloads\\\\test_3.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Detect all faces in image.\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "#Draw a rectangle over the face, and detect eyes in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "    #ROI is region of interest with area having face inside it.\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    \n",
    "    #Detect eyes in face\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imwrite(\"C:\\\\Users\\\\UPPI\\\\Downloads\\\\trial.jpg\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cv2.CascadeClassifier.detectMultiScale() to find faces or eyes, and it is defined like this:\n",
    "\n",
    "cv2.CascadeClassifier.detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) \n",
    "\n",
    "Where the parameters are:\n",
    "\n",
    "image : Matrix of the type CV_8U containing an image where objects are detected.\n",
    "\n",
    "scaleFactor : Parameter specifying how much the image size is reduced at each image scale.This scale factor is used to create scale pyramid as shown in the picture. Suppose, the scale factor is 1.03, it means we're using a small step for resizing, i.e. reduce size by 3 %, we increase the chance of a matching size with the model for detection is found, while it's expensive.\n",
    "\n",
    "minNeighbors : Parameter specifying how many neighbors each candidate rectangle should have to retain it. This parameter will affect the quality of the detected faces: higher value results in less detections but with higher quality. We're using 5 in the code.\n",
    "\n",
    "flags : Parameter with the same meaning for an old cascade as in the function cvHaarDetectObjects. It is not used for a new cascade.\n",
    "\n",
    "minSize : Minimum possible object size. Objects smaller than that are ignored.\n",
    "\n",
    "maxSize : Maximum possible object size. Objects larger than that are ignored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face and Eye Detection using OpenCV on WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture video from webcam\n",
    "video_capture = cv2.VideoCapture(0) #passing 0 to convert to gray \n",
    "\n",
    "#Read all frames from webcam\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    frame = cv2.flip(frame,1) #Flip so that video feed is not flipped, and appears mirror like.\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "#Finally when video capture is over, release the video capture and destroyAllWindows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
